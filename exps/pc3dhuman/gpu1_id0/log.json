2025-05-27 03:31:01 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 03:31:02 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 03:31:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 03:31:57 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 03:50:44 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 03:50:45 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 03:51:33 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 03:51:34 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 03:51:34 Train INFO: training subset: 2 videos, truncated as 5 windows.
2025-05-27 03:51:34 Train INFO: validation subset: 1 videos, truncated as 2 windows.
2025-05-27 03:51:34 Train INFO: validation subset: 1 videos, truncated as 3 windows.
2025-05-27 03:51:37 Train INFO: Using DDP with total 1 GPUS...
2025-05-27 03:51:37 Train INFO: Using Model EMA...
2025-05-27 04:17:41 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 04:17:42 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 04:17:42 Train INFO: training subset: 2 videos, truncated as 5 windows.
2025-05-27 04:17:42 Train INFO: validation subset: 1 videos, truncated as 2 windows.
2025-05-27 04:17:42 Train INFO: validation subset: 1 videos, truncated as 3 windows.
2025-05-27 04:17:44 Train INFO: Using DDP with total 1 GPUS...
2025-05-27 04:17:44 Train INFO: Using Model EMA...
2025-05-27 04:18:07 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 04:18:08 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 04:18:08 Train INFO: training subset: 2 videos, truncated as 5 windows.
2025-05-27 04:18:08 Train INFO: validation subset: 1 videos, truncated as 2 windows.
2025-05-27 04:18:08 Train INFO: validation subset: 1 videos, truncated as 3 windows.
2025-05-27 04:18:11 Train INFO: Using DDP with total 1 GPUS...
2025-05-27 04:18:11 Train INFO: Using Model EMA...
2025-05-27 04:18:11 Train INFO: Training Starts...

2025-05-27 04:18:11 Train INFO: [Train]: Epoch 0 started
2025-05-27 07:37:21 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 07:37:22 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t c -> c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 07:37:22 Train INFO: training subset: 2 videos, truncated as 5 windows.
2025-05-27 07:37:22 Train INFO: validation subset: 1 videos, truncated as 2 windows.
2025-05-27 07:37:22 Train INFO: validation subset: 1 videos, truncated as 3 windows.
2025-05-27 07:37:25 Train INFO: Using DDP with total 1 GPUS...
2025-05-27 07:37:25 Train INFO: Using Model EMA...
2025-05-27 07:37:25 Train INFO: Training Starts...

2025-05-27 07:37:25 Train INFO: [Train]: Epoch 0 started
2025-05-27 08:24:43 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-05-27 08:24:44 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-05-27 08:24:44 Train INFO: training subset: 2 videos, truncated as 5 windows.
2025-05-27 08:24:44 Train INFO: validation subset: 1 videos, truncated as 2 windows.
2025-05-27 08:24:44 Train INFO: validation subset: 1 videos, truncated as 3 windows.
2025-05-27 08:24:46 Train INFO: Using DDP with total 1 GPUS...
2025-05-27 08:24:46 Train INFO: Using Model EMA...
2025-05-27 08:24:46 Train INFO: Training Starts...

2025-05-27 08:24:46 Train INFO: [Train]: Epoch 0 started
2025-06-09 17:36:58 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:36:59 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:37:58 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:38:00 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:38:00 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:38:00 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:38:00 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:38:03 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:38:03 Train INFO: Using Model EMA...
2025-06-09 17:40:11 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:40:13 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:40:13 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:40:13 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:40:13 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:40:16 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:40:16 Train INFO: Using Model EMA...
2025-06-09 17:45:15 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:45:16 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:45:16 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:45:16 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:45:16 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:45:19 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:45:19 Train INFO: Using Model EMA...
2025-06-09 17:47:16 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:47:18 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:47:18 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:47:18 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:47:18 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:47:21 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:47:21 Train INFO: Using Model EMA...
2025-06-09 17:48:19 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:48:21 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:48:21 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:48:21 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:48:21 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:48:24 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:48:24 Train INFO: Using Model EMA...
2025-06-09 17:48:24 Train INFO: Training Starts...

2025-06-09 17:48:24 Train INFO: [Train]: Epoch 0 started
2025-06-09 17:51:06 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:51:08 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        prep_cfg=dict(
            conv_channels=(
                32,
                64,
                128,
            ),
            embed_channels=256,
            input_channels=3),
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:51:08 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:51:08 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:51:08 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:51:10 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:51:10 Train INFO: Using Model EMA...
2025-06-09 17:51:10 Train INFO: Training Starts...

2025-06-09 17:51:10 Train INFO: [Train]: Epoch 0 started
2025-06-09 17:54:14 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:54:16 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1024,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:54:16 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:54:16 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:54:16 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:55:29 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:55:30 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1024,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:55:30 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:55:30 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:55:30 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:56:18 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:56:19 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1024,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:56:19 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:56:19 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:56:19 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:57:16 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:57:17 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1152,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=16, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:57:17 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:57:17 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:57:17 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:57:19 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:57:19 Train INFO: Using Model EMA...
2025-06-09 17:57:19 Train INFO: Training Starts...

2025-06-09 17:57:19 Train INFO: [Train]: Epoch 0 started
2025-06-09 17:58:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 17:58:56 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1152,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=8, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 17:58:56 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 17:58:56 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 17:58:56 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 17:58:58 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 17:58:58 Train INFO: Using Model EMA...
2025-06-09 17:58:59 Train INFO: Training Starts...

2025-06-09 17:58:59 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:03:56 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:03:57 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1152,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:03:57 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:03:57 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:03:57 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:04:00 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:04:00 Train INFO: Using Model EMA...
2025-06-09 18:04:00 Train INFO: Training Starts...

2025-06-09 18:04:00 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:19:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:19:57 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1152,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:19:57 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:19:57 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:19:57 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:19:59 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:19:59 Train INFO: Using Model EMA...
2025-06-09 18:19:59 Train INFO: Training Starts...

2025-06-09 18:19:59 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:25:54 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:25:55 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=1152,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:25:55 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:25:55 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:25:55 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:25:58 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:25:58 Train INFO: Using Model EMA...
2025-06-09 18:25:58 Train INFO: Training Starts...

2025-06-09 18:25:58 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:30:23 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:30:25 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=288,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:30:25 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:30:25 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:30:25 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:33:45 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:33:47 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=576,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:33:47 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:33:47 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:33:47 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:33:49 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:33:49 Train INFO: Using Model EMA...
2025-06-09 18:33:49 Train INFO: Training Starts...

2025-06-09 18:33:49 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:35:29 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:35:30 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=9),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=576,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:35:30 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:35:30 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:35:30 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:36:08 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:36:09 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=9),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:36:09 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:36:09 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:36:09 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:36:11 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:36:11 Train INFO: Using Model EMA...
2025-06-09 18:36:11 Train INFO: Training Starts...

2025-06-09 18:36:11 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:37:25 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:37:26 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:37:26 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:37:26 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:37:26 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:37:28 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:37:28 Train INFO: Using Model EMA...
2025-06-09 18:37:28 Train INFO: Training Starts...

2025-06-09 18:37:28 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:38:53 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:38:55 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:38:55 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:38:55 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:38:55 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:38:57 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:38:57 Train INFO: Using Model EMA...
2025-06-09 18:38:57 Train INFO: Training Starts...

2025-06-09 18:38:57 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:47:04 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:47:05 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:47:05 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:47:05 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:47:05 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:47:08 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:47:08 Train INFO: Using Model EMA...
2025-06-09 18:47:08 Train INFO: Training Starts...

2025-06-09 18:47:08 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:49:33 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:49:34 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:49:34 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:49:34 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:49:34 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:49:37 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:49:37 Train INFO: Using Model EMA...
2025-06-09 18:49:37 Train INFO: Training Starts...

2025-06-09 18:49:37 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:57:22 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:57:23 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:57:23 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:57:23 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:57:23 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:57:25 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:57:25 Train INFO: Using Model EMA...
2025-06-09 18:57:25 Train INFO: Training Starts...

2025-06-09 18:57:25 Train INFO: [Train]: Epoch 0 started
2025-06-09 18:59:45 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 18:59:46 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 18:59:46 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 18:59:46 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 18:59:46 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 18:59:48 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 18:59:48 Train INFO: Using Model EMA...
2025-06-09 18:59:49 Train INFO: Training Starts...

2025-06-09 18:59:49 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:02:21 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:02:23 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:02:23 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:02:23 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:02:23 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:02:25 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:02:25 Train INFO: Using Model EMA...
2025-06-09 19:02:25 Train INFO: Training Starts...

2025-06-09 19:02:25 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:06:09 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:06:11 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:06:11 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:06:11 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:06:11 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:06:13 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:06:13 Train INFO: Using Model EMA...
2025-06-09 19:06:13 Train INFO: Training Starts...

2025-06-09 19:06:13 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:12:11 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:12:12 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:12:12 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:12:12 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:12:12 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:12:14 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:12:14 Train INFO: Using Model EMA...
2025-06-09 19:12:15 Train INFO: Training Starts...

2025-06-09 19:12:15 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:19:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:19:56 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:19:56 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:19:56 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:19:56 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:19:58 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:19:58 Train INFO: Using Model EMA...
2025-06-09 19:19:58 Train INFO: Training Starts...

2025-06-09 19:19:58 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:20:49 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:20:50 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:20:50 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:20:50 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:20:50 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:20:52 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:20:52 Train INFO: Using Model EMA...
2025-06-09 19:20:52 Train INFO: Training Starts...

2025-06-09 19:20:52 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:27:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:27:56 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:27:56 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:27:56 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:27:56 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:27:59 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:27:59 Train INFO: Using Model EMA...
2025-06-09 19:27:59 Train INFO: Training Starts...

2025-06-09 19:27:59 Train INFO: [Train]: Epoch 0 started
2025-06-09 19:31:47 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-09 19:31:49 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-09 19:31:49 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-09 19:31:49 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-09 19:31:49 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-09 19:31:51 Train INFO: Using DDP with total 1 GPUS...
2025-06-09 19:31:51 Train INFO: Using Model EMA...
2025-06-09 19:31:51 Train INFO: Training Starts...

2025-06-09 19:31:51 Train INFO: [Train]: Epoch 0 started
2025-06-10 04:02:18 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 04:02:19 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 04:02:19 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 04:02:19 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 04:02:19 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 04:02:21 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 04:02:21 Train INFO: Using Model EMA...
2025-06-10 04:02:21 Train INFO: Training Starts...

2025-06-10 04:02:21 Train INFO: [Train]: Epoch 0 started
2025-06-10 04:41:08 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 04:41:09 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 04:41:09 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 04:41:09 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 04:41:09 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 04:41:11 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 04:41:11 Train INFO: Using Model EMA...
2025-06-10 04:41:11 Train INFO: Training Starts...

2025-06-10 04:41:11 Train INFO: [Train]: Epoch 0 started
2025-06-10 04:49:36 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 04:49:37 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 04:49:37 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 04:49:37 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 04:49:37 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 04:49:39 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 04:49:39 Train INFO: Using Model EMA...
2025-06-10 04:49:39 Train INFO: Training Starts...

2025-06-10 04:49:39 Train INFO: [Train]: Epoch 0 started
2025-06-10 05:32:11 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 05:32:12 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=256,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 05:32:12 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 05:32:12 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 05:32:12 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 05:32:14 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 05:32:14 Train INFO: Using Model EMA...
2025-06-10 05:32:14 Train INFO: Training Starts...

2025-06-10 05:32:14 Train INFO: [Train]: Epoch 0 started
2025-06-10 06:03:08 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 06:03:09 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 06:03:09 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 06:03:10 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 06:03:10 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 06:03:12 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 06:03:12 Train INFO: Using Model EMA...
2025-06-10 06:03:12 Train INFO: Training Starts...

2025-06-10 06:03:12 Train INFO: [Train]: Epoch 0 started
2025-06-10 06:12:24 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 06:12:25 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 06:12:25 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 06:12:26 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 06:12:26 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 06:13:48 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 06:13:49 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 06:13:49 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 06:13:49 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 06:13:49 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 06:13:51 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 06:13:51 Train INFO: Using Model EMA...
2025-06-10 06:13:51 Train INFO: Training Starts...

2025-06-10 06:13:51 Train INFO: [Train]: Epoch 0 started
2025-06-10 09:07:53 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 09:07:54 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 09:07:54 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 09:07:54 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 09:07:54 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 09:07:56 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 09:07:56 Train INFO: Using Model EMA...
2025-06-10 09:07:56 Train INFO: Training Starts...

2025-06-10 09:07:56 Train INFO: [Train]: Epoch 0 started
2025-06-10 09:18:24 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 09:18:25 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=3, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 09:18:25 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 09:18:25 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 09:18:25 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 09:18:27 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 09:18:27 Train INFO: Using Model EMA...
2025-06-10 09:18:27 Train INFO: Training Starts...

2025-06-10 09:18:27 Train INFO: [Train]: Epoch 0 started
2025-06-10 09:19:21 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 09:19:22 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=3, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 09:19:22 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 09:19:22 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 09:19:22 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 09:19:24 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 09:19:24 Train INFO: Using Model EMA...
2025-06-10 09:19:24 Train INFO: Training Starts...

2025-06-10 09:19:24 Train INFO: [Train]: Epoch 0 started
2025-06-10 09:25:30 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 09:25:31 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=10, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 09:25:31 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 09:25:31 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 09:25:31 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 09:25:33 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 09:25:33 Train INFO: Using Model EMA...
2025-06-10 09:25:33 Train INFO: Training Starts...

2025-06-10 09:25:33 Train INFO: [Train]: Epoch 0 started
2025-06-10 09:34:29 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 09:34:30 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=20,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=30)

2025-06-10 09:34:30 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 09:34:30 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 09:34:30 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 09:34:33 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 09:34:33 Train INFO: Using Model EMA...
2025-06-10 09:34:33 Train INFO: Training Starts...

2025-06-10 09:34:33 Train INFO: [Train]: Epoch 0 started
2025-06-10 09:48:09 Train INFO: [Train]: [000][00001/00001]  Loss=11.6424  cls_loss=6.4991  reg_loss=5.1433  lr_det=1.1e-05  mem=2685MB
2025-06-10 09:48:10 Train INFO: [Train]: Epoch 1 started
2025-06-10 10:01:53 Train INFO: [Train]: [001][00001/00001]  Loss=5.8595  cls_loss=3.3212  reg_loss=2.5383  lr_det=3.3e-05  mem=2685MB
2025-06-10 10:01:54 Train INFO: [Train]: Epoch 2 started
2025-06-10 10:15:40 Train INFO: [Train]: [002][00001/00001]  Loss=3.7630  cls_loss=2.2588  reg_loss=1.5042  lr_det=5.6e-05  mem=2718MB
2025-06-10 10:15:40 Train INFO: [Train]: Epoch 3 started
2025-06-10 10:29:27 Train INFO: [Train]: [003][00001/00001]  Loss=2.5704  cls_loss=1.6731  reg_loss=0.8973  lr_det=7.8e-05  mem=2737MB
2025-06-10 10:29:27 Train INFO: [Train]: Epoch 4 started
2025-06-10 10:36:53 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 10:36:55 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-10 10:36:55 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 10:36:55 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 10:36:55 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 10:36:57 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 10:36:57 Train INFO: Using Model EMA...
2025-06-10 10:36:57 Train INFO: Training Starts...

2025-06-10 10:36:57 Train INFO: [Train]: Epoch 0 started
2025-06-10 10:50:42 Train INFO: [Train]: [000][00001/00001]  Loss=11.6424  cls_loss=6.4991  reg_loss=5.1433  lr_det=1.1e-05  mem=2685MB
2025-06-10 10:50:43 Train INFO: [Train]: Epoch 1 started
2025-06-10 11:04:42 Train INFO: [Train]: [001][00001/00001]  Loss=5.8595  cls_loss=3.3212  reg_loss=2.5383  lr_det=3.3e-05  mem=2685MB
2025-06-10 11:04:43 Train INFO: [Val]: Epoch 1 Loss
2025-06-10 11:15:58 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 11:15:59 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-10 11:15:59 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 11:15:59 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 11:15:59 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 11:16:01 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 11:16:01 Train INFO: Using Model EMA...
2025-06-10 11:16:01 Train INFO: Training Starts...

2025-06-10 11:16:01 Train INFO: [Train]: Epoch 0 started
2025-06-10 11:30:10 Train INFO: [Train]: [000][00001/00001]  Loss=11.6424  cls_loss=6.4991  reg_loss=5.1433  lr_det=1.1e-05  mem=2685MB
2025-06-10 11:30:11 Train INFO: [Train]: Epoch 1 started
2025-06-10 11:44:25 Train INFO: [Train]: [001][00001/00001]  Loss=5.8595  cls_loss=3.3212  reg_loss=2.5383  lr_det=3.3e-05  mem=2685MB
2025-06-10 11:44:26 Train INFO: [Val]: Epoch 1 Loss
2025-06-10 11:50:58 Train INFO: [Val]: [001]  Loss=2.0615  cls_loss=1.1112  reg_loss=0.9503
2025-06-10 11:50:59 Train INFO: New best epoch 1
2025-06-10 11:54:53 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 11:54:54 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(
                keys=[
                    'feats',
                ],
                ops='t x y z c -> x y z c t',
                type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-10 11:54:54 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 11:54:54 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 11:54:54 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 11:54:56 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 11:54:56 Train INFO: Using Model EMA...
2025-06-10 11:54:57 Train INFO: Training Starts...

2025-06-10 11:54:57 Train INFO: [Train]: Epoch 0 started
2025-06-10 12:08:37 Train INFO: [Train]: [000][00001/00001]  Loss=11.6424  cls_loss=6.4991  reg_loss=5.1433  lr_det=1.1e-05  mem=2685MB
2025-06-10 12:08:37 Train INFO: [Train]: Epoch 1 started
2025-06-10 12:22:23 Train INFO: [Train]: [001][00001/00001]  Loss=5.8595  cls_loss=3.3212  reg_loss=2.5383  lr_det=3.3e-05  mem=2685MB
2025-06-10 12:22:23 Train INFO: [Val]: Epoch 1 Loss
2025-06-10 12:28:48 Train INFO: [Val]: [001]  Loss=2.0615  cls_loss=1.1112  reg_loss=0.9503
2025-06-10 12:28:48 Train INFO: New best epoch 1
2025-06-10 13:25:10 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-10 13:25:11 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-10 13:25:11 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-10 13:25:11 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-10 13:25:11 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-10 13:25:13 Train INFO: Using DDP with total 1 GPUS...
2025-06-10 13:25:13 Train INFO: Using Model EMA...
2025-06-10 13:25:13 Train INFO: Training Starts...

2025-06-10 13:25:13 Train INFO: [Train]: Epoch 0 started
2025-06-10 13:38:56 Train INFO: [Train]: [000][00001/00001]  Loss=11.6424  cls_loss=6.4991  reg_loss=5.1433  lr_det=1.1e-05  mem=2685MB
2025-06-10 13:38:57 Train INFO: [Train]: Epoch 1 started
2025-06-10 13:52:48 Train INFO: [Train]: [001][00001/00001]  Loss=5.8595  cls_loss=3.3212  reg_loss=2.5383  lr_det=3.3e-05  mem=2685MB
2025-06-10 13:52:48 Train INFO: [Val]: Epoch 1 Loss
2025-06-10 13:59:11 Train INFO: [Val]: [001]  Loss=2.0615  cls_loss=1.1112  reg_loss=0.9503
2025-06-10 13:59:11 Train INFO: New best epoch 1
2025-06-13 07:49:37 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 07:49:38 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 07:49:38 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 07:49:41 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 07:49:41 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 07:49:41 Test INFO: Checkpoint is epoch 3.
2025-06-13 07:49:41 Test INFO: Using Model EMA...
2025-06-13 07:49:41 Test INFO: Testing Starts...

2025-06-13 08:04:17 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 08:04:18 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 08:04:18 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 08:04:20 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 08:04:20 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 08:04:20 Test INFO: Checkpoint is epoch 3.
2025-06-13 08:04:20 Test INFO: Using Model EMA...
2025-06-13 08:04:20 Test INFO: Testing Starts...

2025-06-13 08:17:55 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 08:17:56 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 08:17:56 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 08:17:58 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 08:17:58 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 08:17:58 Test INFO: Checkpoint is epoch 3.
2025-06-13 08:17:58 Test INFO: Using Model EMA...
2025-06-13 08:17:58 Test INFO: Testing Starts...

2025-06-13 08:19:51 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 08:19:52 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 08:19:52 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 08:19:54 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 08:19:54 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 08:19:55 Test INFO: Checkpoint is epoch 3.
2025-06-13 08:19:55 Test INFO: Using Model EMA...
2025-06-13 08:19:55 Test INFO: Testing Starts...

2025-06-13 10:03:13 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:03:14 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:03:14 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:03:16 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:03:16 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:03:16 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:03:16 Test INFO: Using Model EMA...
2025-06-13 10:03:16 Test INFO: Testing Starts...

2025-06-13 10:03:36 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:03:37 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:03:37 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:03:39 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:03:39 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:03:39 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:03:39 Test INFO: Using Model EMA...
2025-06-13 10:03:39 Test INFO: Testing Starts...

2025-06-13 10:03:57 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:03:58 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:03:58 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:04:00 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:04:00 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:04:01 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:04:01 Test INFO: Using Model EMA...
2025-06-13 10:04:01 Test INFO: Testing Starts...

2025-06-13 10:10:46 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:10:47 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:10:47 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:10:49 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:10:49 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:10:49 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:10:49 Test INFO: Using Model EMA...
2025-06-13 10:10:49 Test INFO: Testing Starts...

2025-06-13 10:21:36 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:21:38 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:21:38 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:21:39 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:21:39 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:21:39 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:21:39 Test INFO: Using Model EMA...
2025-06-13 10:21:39 Test INFO: Testing Starts...

2025-06-13 10:22:13 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:22:14 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:22:14 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:22:16 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:22:16 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:22:16 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:22:16 Test INFO: Using Model EMA...
2025-06-13 10:22:16 Test INFO: Testing Starts...

2025-06-13 10:23:28 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:23:29 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:23:29 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:23:30 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:23:30 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:23:30 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:23:30 Test INFO: Using Model EMA...
2025-06-13 10:23:30 Test INFO: Testing Starts...

2025-06-13 10:27:21 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:27:23 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:27:23 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:27:25 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:27:25 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:27:25 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:27:25 Test INFO: Using Model EMA...
2025-06-13 10:27:25 Test INFO: Testing Starts...

2025-06-13 10:37:37 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 10:37:38 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 10:37:38 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 10:37:40 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 10:37:40 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 10:37:40 Test INFO: Checkpoint is epoch 3.
2025-06-13 10:37:40 Test INFO: Using Model EMA...
2025-06-13 10:37:40 Test INFO: Testing Starts...

2025-06-13 12:00:46 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-13 12:00:47 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-13 12:00:47 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-13 12:00:49 Test INFO: Using DDP with total 1 GPUS...
2025-06-13 12:00:49 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-13 12:00:49 Test INFO: Checkpoint is epoch 3.
2025-06-13 12:00:49 Test INFO: Using Model EMA...
2025-06-13 12:00:49 Test INFO: Testing Starts...

2025-06-15 07:04:45 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:04:46 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:04:46 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:04:48 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:04:48 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:04:49 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:04:49 Test INFO: Using Model EMA...
2025-06-15 07:04:49 Test INFO: Testing Starts...

2025-06-15 07:05:48 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:05:49 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:05:49 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:05:51 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:05:51 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:05:51 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:05:51 Test INFO: Using Model EMA...
2025-06-15 07:05:51 Test INFO: Testing Starts...

2025-06-15 07:07:43 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:07:44 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:07:44 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:07:46 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:07:46 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:07:46 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:07:46 Test INFO: Using Model EMA...
2025-06-15 07:07:46 Test INFO: Testing Starts...

2025-06-15 07:08:11 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:08:13 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:08:13 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:08:14 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:08:14 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:08:15 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:08:15 Test INFO: Using Model EMA...
2025-06-15 07:08:15 Test INFO: Testing Starts...

2025-06-15 07:10:26 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:10:27 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:10:27 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:10:29 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:10:29 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:10:30 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:10:30 Test INFO: Using Model EMA...
2025-06-15 07:10:30 Test INFO: Testing Starts...

2025-06-15 07:12:56 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:12:58 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:12:58 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:13:00 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:13:00 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:13:00 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:13:00 Test INFO: Using Model EMA...
2025-06-15 07:13:00 Test INFO: Testing Starts...

2025-06-15 07:20:06 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:20:07 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:20:07 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:20:09 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:20:09 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:20:09 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:20:10 Test INFO: Using Model EMA...
2025-06-15 07:20:10 Test INFO: Testing Starts...

2025-06-15 07:20:48 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:20:49 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:20:49 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:20:51 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:20:51 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:20:51 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:20:51 Test INFO: Using Model EMA...
2025-06-15 07:20:51 Test INFO: Testing Starts...

2025-06-15 07:28:47 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:28:49 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:28:49 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:28:51 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:28:51 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:28:51 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:28:51 Test INFO: Using Model EMA...
2025-06-15 07:28:51 Test INFO: Testing Starts...

2025-06-15 07:39:07 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:39:08 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:39:08 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:39:10 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:39:10 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:39:10 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:39:10 Test INFO: Using Model EMA...
2025-06-15 07:39:10 Test INFO: Testing Starts...

2025-06-15 07:41:44 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:41:46 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:41:46 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:41:47 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:41:47 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:41:48 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:41:48 Test INFO: Using Model EMA...
2025-06-15 07:41:48 Test INFO: Testing Starts...

2025-06-15 07:44:08 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:44:09 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:44:09 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:44:11 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:44:11 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:44:11 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:44:11 Test INFO: Using Model EMA...
2025-06-15 07:44:11 Test INFO: Testing Starts...

2025-06-15 07:44:52 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 07:44:53 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 07:44:53 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 07:44:55 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 07:44:55 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 07:44:55 Test INFO: Checkpoint is epoch 3.
2025-06-15 07:44:55 Test INFO: Using Model EMA...
2025-06-15 07:44:55 Test INFO: Testing Starts...

2025-06-15 08:20:38 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 08:20:40 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 08:20:40 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 08:20:40 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 08:20:40 Test INFO: Checkpoint is epoch 3.
2025-06-15 08:22:15 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 08:22:16 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 08:22:16 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 08:22:16 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 08:22:17 Test INFO: Checkpoint is epoch 3.
2025-06-15 08:24:09 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 08:24:10 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 08:24:10 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 08:24:12 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 08:24:12 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 08:24:13 Test INFO: Checkpoint is epoch 3.
2025-06-15 08:24:13 Test INFO: Using Model EMA...
2025-06-15 08:24:13 Test INFO: Testing Starts...

2025-06-15 08:24:46 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 08:24:47 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 08:24:47 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 08:24:49 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 08:24:49 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 08:24:49 Test INFO: Checkpoint is epoch 3.
2025-06-15 08:24:49 Test INFO: Using Model EMA...
2025-06-15 08:24:49 Test INFO: Testing Starts...

2025-06-15 08:25:19 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 08:25:20 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 08:25:20 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 08:25:22 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 08:25:22 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 08:25:22 Test INFO: Checkpoint is epoch 3.
2025-06-15 08:25:22 Test INFO: Using Model EMA...
2025-06-15 08:25:22 Test INFO: Testing Starts...

2025-06-15 10:09:08 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 10:09:09 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 10:09:09 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 10:09:12 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 10:09:12 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 10:09:12 Test INFO: Checkpoint is epoch 3.
2025-06-15 10:09:12 Test INFO: Using Model EMA...
2025-06-15 10:09:12 Test INFO: Testing Starts...

2025-06-15 10:13:33 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 10:13:34 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=7, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=7, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 10:13:34 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 10:13:36 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 10:13:36 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 10:13:36 Test INFO: Checkpoint is epoch 3.
2025-06-15 10:13:36 Test INFO: Using Model EMA...
2025-06-15 10:13:36 Test INFO: Testing Starts...

2025-06-15 14:16:22 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 14:16:23 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 14:16:23 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 14:16:25 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 14:16:25 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 14:16:25 Test INFO: Checkpoint is epoch 3.
2025-06-15 14:16:25 Test INFO: Using Model EMA...
2025-06-15 14:16:25 Test INFO: Testing Starts...

2025-06-15 14:35:35 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 14:35:36 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 14:35:36 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 14:35:38 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 14:35:38 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 14:35:39 Test INFO: Checkpoint is epoch 3.
2025-06-15 14:35:39 Test INFO: Using Model EMA...
2025-06-15 14:35:39 Test INFO: Testing Starts...

2025-06-15 15:00:37 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 15:00:38 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 15:00:38 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 15:00:41 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 15:00:41 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 15:00:41 Test INFO: Checkpoint is epoch 3.
2025-06-15 15:00:41 Test INFO: Using Model EMA...
2025-06-15 15:00:41 Test INFO: Testing Starts...

2025-06-15 15:04:35 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 15:04:37 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 15:04:37 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 15:04:39 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 15:04:39 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 15:04:39 Test INFO: Checkpoint is epoch 3.
2025-06-15 15:04:39 Test INFO: Using Model EMA...
2025-06-15 15:04:39 Test INFO: Testing Starts...

2025-06-15 15:07:30 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 15:07:31 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 15:07:31 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 15:07:33 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 15:07:33 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 15:07:33 Test INFO: Checkpoint is epoch 3.
2025-06-15 15:07:33 Test INFO: Using Model EMA...
2025-06-15 15:07:33 Test INFO: Testing Starts...

2025-06-15 15:59:57 Test INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-15 15:59:59 Test INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=256, num_levels=6, out_channels=256, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=4),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=256,
        norm_cfg=dict(type='LN'),
        out_channels=256,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=256,
        in_channels=256,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=20,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=15, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-15 15:59:59 Test INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-15 16:00:01 Test INFO: Using DDP with total 1 GPUS...
2025-06-15 16:00:01 Test INFO: Loading checkpoint from: exps/pc3dhuman/gpu1_id0/checkpoint/epoch_3.pth
2025-06-15 16:00:01 Test INFO: Checkpoint is epoch 3.
2025-06-15 16:00:01 Test INFO: Using Model EMA...
2025-06-15 16:00:01 Test INFO: Testing Starts...

2025-06-22 14:58:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 14:58:56 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=4, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 14:58:56 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 14:58:56 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 14:58:56 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 14:58:58 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 14:58:58 Train INFO: Using Model EMA...
2025-06-22 14:58:58 Train INFO: Training Starts...

2025-06-22 14:58:58 Train INFO: [Train]: Epoch 0 started
2025-06-22 14:59:55 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 14:59:56 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=4, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 14:59:56 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 14:59:56 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 14:59:56 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 14:59:58 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 14:59:58 Train INFO: Using Model EMA...
2025-06-22 14:59:58 Train INFO: Training Starts...

2025-06-22 14:59:58 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:10:51 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:10:53 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=4, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:10:53 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:10:53 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:10:53 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:10:54 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:10:54 Train INFO: Using Model EMA...
2025-06-22 15:10:54 Train INFO: Training Starts...

2025-06-22 15:10:54 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:17:24 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:17:25 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=5, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:17:25 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:17:25 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:17:25 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:17:27 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:17:27 Train INFO: Using Model EMA...
2025-06-22 15:17:27 Train INFO: Training Starts...

2025-06-22 15:17:27 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:20:45 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:20:46 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=5, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:20:46 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:20:46 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:20:46 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:20:48 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:20:48 Train INFO: Using Model EMA...
2025-06-22 15:20:48 Train INFO: Training Starts...

2025-06-22 15:20:48 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:22:32 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:22:33 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=2, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:22:33 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:22:33 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:22:33 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:22:34 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:22:34 Train INFO: Using Model EMA...
2025-06-22 15:22:35 Train INFO: Training Starts...

2025-06-22 15:22:35 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:23:03 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:23:05 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=128, num_levels=5, out_channels=128, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=128,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=128,
        in_channels=128,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:23:05 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:23:05 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:23:05 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:23:06 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:23:06 Train INFO: Using Model EMA...
2025-06-22 15:23:06 Train INFO: Training Starts...

2025-06-22 15:23:06 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:25:50 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:25:51 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=64, num_levels=5, out_channels=64, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=64,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=64,
        in_channels=64,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:25:51 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:25:51 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:25:51 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:25:53 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:25:53 Train INFO: Using Model EMA...
2025-06-22 15:25:53 Train INFO: Training Starts...

2025-06-22 15:25:53 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:26:26 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:26:27 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=64, num_levels=5, out_channels=64, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=64,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=64,
        in_channels=64,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:26:27 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:26:27 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:26:27 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:26:29 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:26:29 Train INFO: Using Model EMA...
2025-06-22 15:26:29 Train INFO: Training Starts...

2025-06-22 15:26:29 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:27:14 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:27:15 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=64, num_levels=5, out_channels=64, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=64,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=64,
        in_channels=64,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:27:15 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:27:15 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:27:15 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:27:39 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:27:41 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=64, num_levels=5, out_channels=64, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=17),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=64,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=64,
        in_channels=64,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:27:41 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:27:41 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:27:41 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:27:42 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:27:42 Train INFO: Using Model EMA...
2025-06-22 15:27:42 Train INFO: Training Starts...

2025-06-22 15:27:42 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:28:27 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:28:29 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=64, num_levels=5, out_channels=64, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=1152,
        norm_cfg=dict(type='LN'),
        out_channels=64,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=64,
        in_channels=64,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:28:29 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:28:29 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:28:29 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:28:30 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:28:30 Train INFO: Using Model EMA...
2025-06-22 15:28:30 Train INFO: Training Starts...

2025-06-22 15:28:30 Train INFO: [Train]: Epoch 0 started
2025-06-22 15:37:49 Train INFO: Using torch version: 2.1.0+cu121, CUDA version: 12.1
2025-06-22 15:37:50 Train INFO: Config: 
annotation_path = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json'
block_list = '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt'
class_map = '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt'
data_path = '/tad_work/OpenTAD/data/pc3dhumanact2/features/'
dataset = dict(
    test=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(keys=[
                'feats',
            ], type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(inputs='feats', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        test_mode=True,
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=1024),
    train=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024),
    val=dict(
        ann_file='/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
        block_list=
        '/tad_work/OpenTAD/data/pc3dhumanact2/features/missing_files.txt',
        class_map=
        '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/category_idx.txt',
        data_path='/tad_work/OpenTAD/data/pc3dhumanact2/features/',
        feature_stride=4,
        filter_gt=False,
        offset_frames=8,
        pipeline=[
            dict(feat_format='npy', type='LoadFeats'),
            dict(
                keys=[
                    'feats',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(type='SlidingWindowTrunc', with_mask=True),
            dict(keys=[
                'feats',
            ], ops='t n c -> n c t', type='Rearrange'),
            dict(
                inputs='feats',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='ThumosSlidingDataset',
        window_overlap_ratio=0.25,
        window_size=1024))
dataset_type = 'ThumosSlidingDataset'
evaluation = dict(
    ground_truth_filename=
    '/tad_work/OpenTAD/data/pc3dhumanact2/annotations/anno.json',
    subset='validation',
    tiou_thresholds=[
        0.3,
        0.4,
        0.5,
        0.6,
        0.7,
    ],
    type='mAP')
inference = dict(load_from_raw_predictions=False, save_raw_prediction=False)
model = dict(
    neck=dict(
        in_channels=64, num_levels=5, out_channels=64, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=2, n_mha_win_size=19),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=128,
        max_seq_len=2304,
        norm_cfg=dict(type='LN'),
        out_channels=64,
        path_pdrop=0.1,
        type='PCTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=64,
        in_channels=64,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=7,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(lr=0.0001, paramwise=True, type='AdamW', weight_decay=0.05)
post_processing = dict(
    nms=dict(
        iou_threshold=0.1,
        max_seg_num=2000,
        min_score=0.001,
        multiclass=True,
        sigma=0.5,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=False)
scheduler = dict(
    max_epoch=35, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    clip_grad_norm=1,
    ema=True,
    test=dict(batch_size=1, num_workers=1),
    train=dict(batch_size=1, num_workers=2),
    val=dict(batch_size=1, num_workers=1))
window_size = 1024
work_dir = 'exps/pc3dhuman/gpu1_id0/'
workflow = dict(
    checkpoint_interval=1,
    logging_interval=1,
    val_eval_interval=1,
    val_loss_interval=1,
    val_start_epoch=1)

2025-06-22 15:37:50 Train INFO: training subset: 9 videos, truncated as 29 windows.
2025-06-22 15:37:50 Train INFO: validation subset: 2 videos, truncated as 7 windows.
2025-06-22 15:37:50 Train INFO: validation subset: 2 videos, truncated as 10 windows.
2025-06-22 15:37:52 Train INFO: Using DDP with total 1 GPUS...
2025-06-22 15:37:52 Train INFO: Using Model EMA...
2025-06-22 15:37:52 Train INFO: Training Starts...

2025-06-22 15:37:52 Train INFO: [Train]: Epoch 0 started
